{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538d0919",
   "metadata": {},
   "source": [
    "### Priting the iamge and its Dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4f7d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height = 879 , Width = 772.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"images/my_image2.jpg\")\n",
    "\n",
    "x , y = image.shape[:2]\n",
    "print(\"Height = {} , Width = {}.ipynb_checkpoints\".format(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87283854",
   "metadata": {},
   "source": [
    "#### Extrcting the RGB values form the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371e8e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R = 85 ,G = 79,B = 96\n",
      "just the values of B = 85\n"
     ]
    }
   ],
   "source": [
    "(R,G,B) = image[250,250] \n",
    "print(\"R = {} ,G = {},B = {}\".format(R,G,B))\n",
    "\n",
    "B = image[250,250,0]\n",
    "print(\"just the values of B = {}\".format(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df4e7b",
   "metadata": {},
   "source": [
    "### Resizing the image to any dimentions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3360f465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175 175 176 ...  75  75  75]\n",
      " [175 175 176 ...  75  75  75]\n",
      " [176 176 176 ...  75  75  75]\n",
      " ...\n",
      " [ 62  63  63 ...  46  46  46]\n",
      " [ 62  62  62 ...  45  45  45]\n",
      " [ 62  62  63 ...  45  45  45]] [[143 143 144 ...  62  62  62]\n",
      " [143 143 144 ...  62  62  62]\n",
      " [143 143 143 ...  63  63  63]\n",
      " ...\n",
      " [ 30  31  31 ...  24  24  24]\n",
      " [ 30  30  30 ...  23  23  23]\n",
      " [ 30  30  31 ...  23  23  23]] [[161 161 162 ...  88  88  88]\n",
      " [161 161 162 ...  88  88  88]\n",
      " [162 162 162 ...  90  90  90]\n",
      " ...\n",
      " [ 43  44  44 ...  34  34  34]\n",
      " [ 43  43  43 ...  33  33  33]\n",
      " [ 43  43  44 ...  33  33  33]]\n",
      "[[[175 161 143]\n",
      "  [175 161 143]\n",
      "  [176 162 144]\n",
      "  ...\n",
      "  [ 75  88  62]\n",
      "  [ 75  88  62]\n",
      "  [ 75  88  62]]\n",
      "\n",
      " [[175 161 143]\n",
      "  [175 161 143]\n",
      "  [176 162 144]\n",
      "  ...\n",
      "  [ 75  88  62]\n",
      "  [ 75  88  62]\n",
      "  [ 75  88  62]]\n",
      "\n",
      " [[176 162 143]\n",
      "  [176 162 143]\n",
      "  [176 162 143]\n",
      "  ...\n",
      "  [ 75  90  63]\n",
      "  [ 75  90  63]\n",
      "  [ 75  90  63]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 62  43  30]\n",
      "  [ 63  44  31]\n",
      "  [ 63  44  31]\n",
      "  ...\n",
      "  [ 46  34  24]\n",
      "  [ 46  34  24]\n",
      "  [ 46  34  24]]\n",
      "\n",
      " [[ 62  43  30]\n",
      "  [ 62  43  30]\n",
      "  [ 62  43  30]\n",
      "  ...\n",
      "  [ 45  33  23]\n",
      "  [ 45  33  23]\n",
      "  [ 45  33  23]]\n",
      "\n",
      " [[ 62  43  30]\n",
      "  [ 62  43  30]\n",
      "  [ 63  44  31]\n",
      "  ...\n",
      "  [ 45  33  23]\n",
      "  [ 45  33  23]\n",
      "  [ 45  33  23]]]\n"
     ]
    }
   ],
   "source": [
    "(r , g, b) = cv2.split(image)\n",
    "print(r,b,g)\n",
    "\n",
    "image = cv2.merge((r,g,b))\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9e4891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 3024, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "#importing the opencv module  \n",
    "import cv2  \n",
    "# using imread('path') and 1 denotes read as  color image  \n",
    "img = cv2.imread('images/ikrash1.jpg',1)  \n",
    "print(img.shape)\n",
    "img_resized=cv2.resize(img, (780, 540),  \n",
    "               interpolation = cv2.INTER_NEAREST) \n",
    "cv2.imshow(\"Resized\",img_resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf09b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 3024, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "#importing the opencv module  \n",
    "import cv2  \n",
    "# using imread('path') and 1 denotes read as  color image  \n",
    "img = cv2.imread('images/ikrash1.jpg',1)  \n",
    "print(img.shape)\n",
    "image = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE) \n",
    "cv2.imshow(\"Rotated\",image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cee4322e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.70710678    0.70710678 -153.85908987]\n",
      " [  -0.70710678    0.70710678  600.55129855]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "#importing the opencv module  \n",
    "import cv2  \n",
    "# using imread('path') and 1 denotes read as  color image  \n",
    "img = cv2.imread('images/my_image3.jpeg',1)  \n",
    "# get image height, width\n",
    "(h, w) = img.shape[:2]\n",
    "# calculate the center of the image\n",
    "center = (w / 2, h / 2)\n",
    "  \n",
    "scale = 1.0\n",
    "  \n",
    "# Perform the counter clockwise rotation holding at the center\n",
    "# 45 degrees\n",
    "M = cv2.getRotationMatrix2D(center, 45, scale)\n",
    "print(M)\n",
    "rotated45 = cv2.warpAffine(img, M, (h, w))\n",
    "  \n",
    "# 110 degrees\n",
    "M = cv2.getRotationMatrix2D(center,110, scale)\n",
    "rotated110 = cv2.warpAffine(img, M, (w, h))\n",
    "  \n",
    "# 150 degrees\n",
    "M = cv2.getRotationMatrix2D(center, 150, scale)\n",
    "rotated150 = cv2.warpAffine(img, M, (h, w))\n",
    "  \n",
    "  \n",
    "cv2.imshow('Original Image',img)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image\n",
    "  \n",
    "cv2.imshow('Image rotated by 45 degrees',rotated45)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image\n",
    "  \n",
    "cv2.imshow('Image rotated by 110 degrees',rotated110)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image\n",
    "  \n",
    "cv2.imshow('Image rotated by 150 degrees',rotated150)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51e45634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "img = cv2.imread(r'images/lobab2.jpg', 1)  \n",
    "cv2.circle(img,(500,500), 400, (255,0,0), 1)  \n",
    "cv2.imshow('image',img)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ebd50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "img = cv2.imread(r'images/my_image4.JPG', 1)  \n",
    "cv2.rectangle(img,(350,55),(550,250),(0,255,0),5)  \n",
    "cv2.imshow('image',img)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7774a4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  \n",
    "mg = cv2.imread(r'images/ikrash3.jpg', 1)  \n",
    "cv2.putText(img,'Ikrash khan',(10,500), font, 1,(255,255,255),10)  \n",
    "#Display the image  \n",
    "cv2.imshow(\"image\",mg)  \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38e7ad21",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m ret, frames \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread() \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# convert to gray scale of each frames \u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frames, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY) \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Detects cars of different sizes in the input image \u001b[39;00m\n\u001b[0;32m     21\u001b[0m cars \u001b[38;5;241m=\u001b[39m car_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray, \u001b[38;5;241m1.1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# OpenCV Python program to detect cars in video frame \n",
    "# import libraries of python OpenCV  \n",
    "import cv2 \n",
    "   \n",
    "# capture frames from a video \n",
    "cap = cv2.VideoCapture('video.avi') \n",
    "   \n",
    "# Trained XML classifiers describes some features of some object we want to detect \n",
    "car_cascade = cv2.CascadeClassifier('cars.xml') \n",
    "   \n",
    "# loop runs if capturing has been initialized. \n",
    "while True: \n",
    "    # reads frames from a video \n",
    "    ret, frames = cap.read() \n",
    "       \n",
    "    # convert to gray scale of each frames \n",
    "    gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY) \n",
    "       \n",
    "   \n",
    "    # Detects cars of different sizes in the input image \n",
    "    cars = car_cascade.detectMultiScale(gray, 1.1, 1) \n",
    "       \n",
    "    # To draw a rectangle in each cars \n",
    "    for (x,y,w,h) in cars: \n",
    "        cv2.rectangle(frames,(x,y),(x+w,y+h),(0,0,255),2) \n",
    "   \n",
    "   # Display frames in a window  \n",
    "    cv2.imshow('video2', frames) \n",
    "       \n",
    "    # Wait for Esc key to stop \n",
    "    if cv2.waitKey(33) == 27: \n",
    "        break\n",
    "   #De-allocate any associated memory usage \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe17052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open video.\n",
      "Error: Failed to read frame.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to video file or device index (0 for the default webcam)\n",
    "video_source = 'path_to_your_video_file_or_device_index'\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Load the pre-trained cascade classifier for car detection\n",
    "car_cascade = cv2.CascadeClassifier('haarcascade_car.xml')\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frames = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert to gray scale of each frame\n",
    "    gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detects cars of different sizes in the input image\n",
    "    cars = car_cascade.detectMultiScale(gray, 1.1, 1)\n",
    "\n",
    "    # Draw rectangles around the cars\n",
    "    for (x, y, w, h) in cars:\n",
    "        cv2.rectangle(frames, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frames)\n",
    "\n",
    "    # Break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c0845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
